---
title: '[Inference] Maximum Likelihood Estimator'
date: 2023-05-24 15:33:00 +0000
categories: [Inference, MLE]
tags: [MLE]
math: true
---

## Definition
For observation $x$ and unknown parameter $\theta$ with likelihood function $L(\theta;x)$, then the maximum likelihood estimator is defined as the value of $\theta$ at which $L(\theta;x)$ attains the maximum: $$\hat{\theta}_{MLE} = argmax_{\theta}L(\theta; x)$$

## Properties
1. Invariant to transformation. If $$\hat{\theta}_{MLE}$$ is MLE of $\theta$, then the MLE for any function $T(\theta)$ is $T(\hat{\theta}_{MLE})$

2. Asymptotically follows normal distribution 

3. Consistent; Under some regularity conditions, MLE is consistent and efficient

4. Obey likelihood principle. If $L(\theta;x) = h(x,y)L(\theta;y)$, then $\hat{\theta}_{MLE}(x) = \hat{\theta}_{MLE}(y)$

5. Does not guarantee unbiased and efficiency 

(As n goes to $\infty$, MLE is both unbiased and efficient)

CRLB suggests the MLE typically satisfies an asymptotic version of UMVUE optimal property


*Example: Uniform Random Variables*

What is the MLE for unknown parameter $\theta$ when $x_1, ... x_n$ is i.i.d $Unif(0, \theta)$ distributed random variables $\theta \> 0)$


Step1. Find likelihood 

$ L(\theta; x) = \frac{1}{\theta^n}I(\theta \geq x_{(n)})$


As the function $1/\theta^n$ is a monotonic decreasing function of $\theta$, the smaller $\theta$ will have the larger $1/\theta^n$ . However, if the value of $\theta$ is smaller than $x_{(n)}$, the likelihood $L(\theta; x)$ would be zero. Therefore, $\hat{\theta}_{MLE} = x_{(n)}$

*Example2: Normal Distribution*

What is the MLE for unknown parameter $\mu$ and $\sigma^{2}$ when $x_1, ... x_n$ is i.i.d $N(\mu, \sigma^{2})$ distributed random variable?


Step1. Find Likelihood

$L(\mu, \sigma^2;x) = \prod_{i=1}^{n} \frac{1}{\sigma \sqrt{2\pi}} e^{-\frac{(x_i-\mu)^2}{2\sigma^2}}
= (frac{1}{\sigma \sqrt{2\pi}})^{n} e^{-\sum_{i=1}^{n}\frac{(x_i-\mu)^2}{2\sigma^2}}$

Step2. Find log-likelihood

$l(\mu, \sigma^2;x) = -frac{n}{2}log(2\pi) - \frac{n}{2}log(\sigma^{2}) + {-\sum_{i=1}^{n}\frac{(x_i-\mu)^2}{2\sigma^2}}$


Step3. Take derivaties


3.1 w.r.t $\mu$: $\frac{\delta}{\delta\mu}l(\mu, \sigma^2; x) = -\frac{\sum 2(\mu - x_i)}{2\sigma^2} = -frac{n\mu - \sum x_i}{\sigma^2}$

3.2 w.r.t $\sigma$: $\frac{\delta}{\delta\sigma^2}l(\mu, \sigma^2; x) = -\frac{n}{2\sigma^2} + \frac{\sum(x - \mu)^{2}}{2 \sigma^4}$

Step4. Find the parameter values when the derivatie equals 0 

$-frac{n\mu - \sum x_i}{\sigma^2} = 0$ and $-\frac{n}{2\sigma^2} + \frac{\sum(x - \mu)^{2}}{2 \sigma^4} = 0$

Therefore, $\hat{\mu} = \bar{x}$ and $\hat{\sigma^{2}} = \frac{\sum(x_i - \bar{x})^{2}}{n}$






